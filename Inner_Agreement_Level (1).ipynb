{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["f9c0278739d44384b7f6115f81132b4d","50484306835d4769a0b1673e5714f806","df4ed84568604c3d8c92dbb916dca9ed","ea500a17b2b3442bbf3134204e4f4b3d","1be51764ff774179a1a1e319065b1185","6d7b346751d64e54bb4ba26d4816614e","e5f6daf417fb4c32bd32dddc8f7068cd","98084dd939f54783922716cf0a2835ed","7a584de7b2d2485e85ab4786ae9df0d8"]},"executionInfo":{"elapsed":2273,"status":"ok","timestamp":1691513901423,"user":{"displayName":"Guy Maduel","userId":"09611909448416655001"},"user_tz":-180},"id":"8qA0l6kZZJdZ","outputId":"3d1c0386-eb8b-4c94-b492-ff2fc8bdd5e7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Text(value='Please click Upload to upload your CSV file', continuous_update=False, disabled=True, layout=Layouâ€¦"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9c0278739d44384b7f6115f81132b4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["FileUpload(value={}, accept='.csv', description='Upload')"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea500a17b2b3442bbf3134204e4f4b3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Button(description='Run', style=ButtonStyle())"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f6daf417fb4c32bd32dddc8f7068cd"}},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","from collections import Counter\n","import ipywidgets as widgets\n","from IPython.display import display, clear_output\n","import os as sys\n","import io\n","import pandas as pd\n","from sklearn.metrics import cohen_kappa_score\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import ast\n","\n","#@title Calculating annotators inner agreement level\n","#@markdown # **Instructions**\n","#@markdown Please make sure you have an available csv file on your main folder on google drive (\"MyDrive\")\n","#@markdown Make sure to name it \"screenshot.csv\"\n","\n","#@markdown Alternatively, you can directly upload a csv file by pressing Upload.  **Note:**\n","#@markdown * You'll Need to first press the Play button.\n","#@markdown * this process might take some time.\n","\n","\n","#@markdown  # Please press on the Play button on the left to begin.\n","#@markdown After pressing Play and providing the csv, press Run to start.\n","\n","# Add instruction for the user\n","output = widgets.Output()\n","name_box = widgets.Text(\n","    value=\"Please click Upload to upload your CSV file\",\n","    continuous_update=False,\n","    disabled=True,\n","    layout=widgets.Layout(width='auto')\n",")\n","# Create a FileUpload widget\n","uploader = widgets.FileUpload(\n","    accept='.csv',  # Accepted file type\n","    multiple=False  # True to accept multiple files upload else False\n",")\n","# Create a Run button widget\n","run_button = widgets.Button(description='Run')\n","\n","def on_run_click(b):\n","  global data\n","  # Get the uploaded file\n","  if len(uploader.value) > 0:\n","    uploaded_file = uploader.value[list(uploader.value.keys())[0]]\n","    content = uploaded_file['content']\n","    #Convert the uploaded file to a dataframe\n","    data = pd.read_csv(io.BytesIO(content))\n","  else:\n","    drive.mount('/content/drive')\n","    csv_path = ('/content/drive/MyDrive/screenshot.csv')\n","    data = pd.read_csv(csv_path)\n","  # Hide the FileUpload widget and the instruction text\n","  name_box.layout.display = 'none'\n","  uploader.layout.display = 'none'\n","  run_button.layout.display = 'none'\n","  clear_output()\n","\n","  # Call the displaySecondMenu function\n","  displaySecondMenu(data)\n","\n","# Add an event listener to the Run button\n","run_button.on_click(on_run_click)\n","# Display the uploader and the instruction text\n","display(name_box, uploader, run_button)\n","\n","\n","#secondary menu\n","def displaySecondMenu(data):\n","  annotators = load_annotators(data)\n","  tasks = create_tasks(data)\n","  # Create dropdown widgets for annotator selection\n","  annotator1_dropdown = widgets.Dropdown(options= annotators, description='Annotator1:')\n","  annotator2_dropdown = widgets.Dropdown(options= annotators, description='Annotator2:')\n","\n","  # Create dropdown widget for task selection\n","  task_dropdown = widgets.Dropdown(options=tasks, description='Task:')\n","\n","  # Create a button widget for calculating cohen kappa\n","  calc_button = widgets.Button(description='Calculate Agreement')\n","\n","  # Define a callback function for the button Calculate Agreement\n","  def on_calc_agreement_click(b):\n","    clear_output()\n","    annotator_a = annotator1_dropdown.value\n","    annotator_b = annotator2_dropdown.value\n","    taskChoice = task_dropdown.value\n","    task = 'sentiment' if taskChoice == \"Sentiment\" else 'emotions' if taskChoice == \"Emotions\" else 'label' if taskChoice == \"NER\" else 'Stats' if taskChoice == 'Stats' else None\n","    display(annotator1_dropdown, annotator2_dropdown,\n","        task_dropdown, calc_button, output)\n","    calc_agreement(data,annotator_a,annotator_b,task)\n","\n","  # Register the callback function with the button save\n","  calc_button.on_click(on_calc_agreement_click)\n","  # Display the Menu\n","  output = widgets.Output()\n","  display(annotator1_dropdown, annotator2_dropdown,\n","        task_dropdown, calc_button, output)\n","\n","\n","\n","\n","\n","\n","#Utility functions\n","def load_annotators(data):\n","    data = data[data['annotator'].notnull()]\n","    return  np.unique(data['annotator'].dropna().values)\n","\n","def create_tasks(data):\n","  tasks = ['Stats']\n","  if 'sentiment' in data.columns:\n","    tasks.append('Sentiment')\n","  if 'emotions' in data.columns:\n","      tasks.append('Emotions')\n","  if 'label' in data.columns:\n","      tasks.append('NER')\n","  return tasks\n","\n","def filter_following_sentences(data):\n","    filtered_data = data[data['Connected_sentence'].isnull()]\n","    return filtered_data\n","\n","def filter_by_annotator(data, annotator):\n","    filtered_data = data[data['annotator'] == annotator].copy()\n","    filtered_data= filtered_data.drop_duplicates(subset=['annotator','id'])\n","    annotator_a_data_filtered = filtered_data[['id', 'sentiment', 'label', 'emotions','Connected_sentence']].copy()\n","    return annotator_a_data_filtered\n","\n","def get_vmin_vmax(confusion_matrix):\n","    min_val = confusion_matrix.min().min()\n","    max_val = confusion_matrix.max().max()\n","    avg_val = confusion_matrix.mean().mean()\n","\n","    if max_val > min_val + 200:\n","        # Use the min-max method otherwise\n","        vmin = min_val\n","        vmax = (avg_val + min_val + max_val) / 3\n","\n","    else:\n","        # Use the IQR method if there are values significantly far from the mean\n","        q1 = np.percentile(confusion_matrix, 25)\n","        q3 = np.percentile(confusion_matrix, 75)\n","        iqr = q3 - q1\n","        vmin = max(0, q1 - 1.5 * iqr)\n","        vmax = q3 + 1.5 * iqr\n","\n","    return vmin, vmax\n","\n","def transform_column(id_column, label_column):\n","    rows = []\n","    for id_value, label_value in zip(id_column, label_column):\n","        label_value = ast.literal_eval(label_value)\n","        for annotation in label_value:\n","            row = {}\n","            row['id'] = id_value\n","            row['label1'] = annotation\n","            row['text'] = annotation['text']\n","            row['task1'] = annotation['labels'][0]\n","            row['Interval'] = (annotation['start'], annotation['end'])\n","            rows.append(row)\n","    df = pd.DataFrame(rows)\n","    return df\n","\n","def interval_intersection(a, b):\n","    start = max(a[0], b[0])\n","    end = min(a[1], b[1])\n","    if start < end:\n","        return (start, end)\n","    else:\n","        return None\n","\n","\n","## for verification dive the annotator filtered data and the new data frame of the same annotator alone\n","def verify_counts(data, df):\n","    for id_value in data['id'].dropna().unique():\n","        label_value = data.loc[data['id'] == id_value, 'label'].iloc[0]\n","        label_value = ast.literal_eval(label_value)\n","        num_tasks = len(label_value)\n","        num_rows = len(df.loc[df['id'] == id_value])\n","        if num_tasks != num_rows:\n","            print(f\"Error: id {id_value} has {num_tasks} tasks but {num_rows} rows\")\n","            return False\n","    #print(\"Verification successful\")\n","    return True\n","\n","def calculate_metrics(annotator_a_data, annotator_b_data, partial_ratio_threshold=0.5):\n","    # Initialize list to store results\n","    results = []\n","\n","    # Loop through samples\n","    for id_value in annotator_a_data['id'].unique():\n","        # Get annotations for current sample\n","        a_annotations = annotator_a_data[annotator_a_data['id'] == id_value]\n","        b_annotations = annotator_b_data[annotator_b_data['id'] == id_value]\n","\n","        # Loop through annotations from annotator A\n","        for _, a_annotation in a_annotations.iterrows():\n","            result = {\n","                'id': id_value,\n","                'Annotator A Entity Type': a_annotation['task1'],\n","                'Annotator A Surface String': a_annotation['text'],\n","                'Annotator B Entity Type': '',\n","                'Annotator B Surface String': '',\n","                'Type': 'MIS',\n","                'Partial': 'MIS',\n","                'Exact': 'MIS',\n","                'Strict': 'MIS'\n","            }\n","\n","            # Check if there is an overlapping annotation from annotator B\n","            overlap = False\n","            for _, b_annotation in b_annotations.iterrows():\n","                intersection = interval_intersection(a_annotation['Interval'], b_annotation['Interval'])\n","                if intersection is not None:\n","                    overlap = True\n","                    result['Annotator B Entity Type'] = b_annotation['task1']\n","                    result['Annotator B Surface String'] = b_annotation['text']\n","                    if a_annotation['task1'] == b_annotation['task1']:\n","                        result['Type'] = 'COR'\n","                        if a_annotation['text'] == b_annotation['text']:\n","                            result['Exact'] = 'COR'\n","                            result['Strict'] = 'COR'\n","                        else:\n","                            result['Exact'] = 'INC'\n","                            result['Strict'] = 'INC'\n","                    else:\n","                        result['Type'] = 'INC'\n","                        result['Strict'] = 'INC'\n","                        if a_annotation['text'] == b_annotation['text']:\n","                            result['Exact'] = 'COR'\n","                        else:\n","                            result['Exact'] = 'INC'\n","\n","                    # Calculate ratio of intersection\n","                    intersection_length = intersection[1] - intersection[0]\n","                    a_length = a_annotation['Interval'][1] - a_annotation['Interval'][0]\n","                    b_length = b_annotation['Interval'][1] - b_annotation['Interval'][0]\n","                    ratio = 2 * intersection_length / (a_length + b_length)\n","                    if ratio >= partial_ratio_threshold:\n","                        result['Partial'] = 'PAR'\n","                    else:\n","                        result['Partial'] = result['Exact']\n","\n","                    break\n","\n","            results.append(result)\n","\n","        # Count spurious annotations from annotator B\n","        for _, b_annotation in b_annotations.iterrows():\n","            overlap = False\n","            for _, a_annotation in a_annotations.iterrows():\n","                if interval_intersection(a_annotation['Interval'], b_annotation['Interval']) is not None:\n","                    overlap = True;\n","                    break;\n","            if not overlap:\n","                result = {\n","                    'id': id_value,\n","                    'Annotator A Entity Type': '',\n","                    'Annotator A Surface String': '',\n","                    'Annotator B Entity Type': b_annotation['task1'],\n","                    'Annotator B Surface String': b_annotation['text'],\n","                    'Type': 'SPU',\n","                    'Partial': 'SPU',\n","                    'Exact': 'SPU',\n","                    'Strict': 'SPU'\n","                }\n","                results.append(result)\n","\n","    return pd.DataFrame(results)\n","\n","def calculate_scores(results_df):\n","    # Calculate number of gold-standard annotations\n","    pos = (results_df['Type'] != 'SPU').sum()\n","\n","    # Calculate number of annotations produced by the NER system\n","    act = (results_df['Type'] != 'MIS').sum()\n","\n","    # Initialize dictionary to store scores\n","    scores = {\n","        'Measure': ['Correct', 'Incorrect', 'Partial', 'Missed', 'Spurius', 'Precision', 'Recall', 'F1']\n","    }\n","\n","    # Calculate scores for each evaluation schema\n","    for schema in ['Type', 'Partial', 'Exact', 'Strict']:\n","        # Calculate number of correct, incorrect, partial, missed, and spurious annotations\n","        cor = (results_df[schema] == 'COR').sum()\n","        inc = (results_df[schema] == 'INC').sum()\n","        par = (results_df[schema] == 'PAR').sum()\n","        mis = (results_df[schema] == 'MIS').sum()\n","        spu = (results_df[schema] == 'SPU').sum()\n","\n","        # Calculate precision and recall\n","        if schema == 'Partial':\n","            precision = (cor + par) / act\n","            recall = (cor + par) / pos\n","        else:\n","            precision = cor / act\n","            recall = cor / pos\n","\n","        # Calculate F1-score\n","        f1 = 2 * precision * recall / (precision + recall)\n","\n","        # Store scores\n","        scores[schema] = ['{:.0f}'.format(cor), inc, par, mis, spu, precision, recall, f1]\n","\n","    return pd.DataFrame(scores)\n","\n","\n","\n","def cal_average_NER(scores_dfA, scores_dfB):\n","    average = scores_dfA.copy()\n","    average.iloc[:8, 1:] = ((scores_dfA.iloc[:8, 1:].copy().astype(float) + scores_dfB.iloc[:8, 1:].copy().astype(float))) / 2\n","    average.iloc[:5, 1:] = average.iloc[:5, 1:].astype(str)\n","    return average.tail(3)\n","\n","\n","\n","def labelcalc():\n","    global dfa\n","    global dfb\n","    id_column_a = annotator_a_task['id'].dropna()\n","    label_column_a = annotator_a_task['label'].dropna()\n","    dfa = transform_column(id_column_a, label_column_a)\n","    id_column_b = annotator_b_task['id'].dropna()\n","    label_column_b = annotator_b_task['label'].dropna()\n","    dfb = transform_column(id_column_b, label_column_b)\n","    #if verify_counts(annotator_a_task, dfa) and verify_counts(annotator_b_task, dfb):\n","    results_dfA = calculate_metrics(dfa, dfb)\n","    results_dfB = calculate_metrics(dfb, dfa)\n","    scores_dfA = calculate_scores(results_dfA)\n","    scores_dfB = calculate_scores(results_dfB)\n","    display(cal_average_NER(scores_dfA, scores_dfB))\n","\n","def display_stats(data):\n","    null_data = data[data['id'].isna()]\n","    nonnull_data = data[data['id'].notna()]\n","    nonnull_data = nonnull_data.drop_duplicates(subset='id')\n","    unique_data = pd.concat([null_data,nonnull_data])\n","    overall_samples =  unique_data.shape[0]\n","    id_counts = data['id'].value_counts()\n","    annotated_more_than_one = sum(id_counts > 1)\n","    print(f\"\\n\\n There are overall {data.shape[0]} annotations over {overall_samples} samples.\\n {annotated_more_than_one} samples were annotated by more than a single annotator. \\n\\n\")\n","    number_of_annotations_a = annotator_a_data.shape[0]\n","    number_of_annotations_b = annotator_b_data.shape[0]\n","    number_of_annotations_a_connected_s = filter_following_sentences(annotator_a_data).shape[0]\n","    number_of_annotations_b_connected_s = filter_following_sentences(annotator_b_data).shape[0]\n","    annotator_a_emotions_notnull = annotator_a_data[annotator_a_data['emotions'].notnull()].shape[0]\n","    annotator_b_emotions_notnull = annotator_b_data[annotator_b_data['emotions'].notnull()].shape[0]\n","    annotator_a_sentiment_notnull = annotator_a_data[annotator_a_data['sentiment'].notnull()].shape[0]\n","    annotator_b_sentiment_notnull = annotator_b_data[annotator_b_data['sentiment'].notnull()].shape[0]\n","    joined_data = pd.merge(annotator_a_data, annotator_b_data,on='id', how='inner', suffixes=('_a', '_b'))\n","    joined_data_filtered = joined_data[['id', 'sentiment_a', 'sentiment_b','emotions_a','emotions_b']]\n","    num_overlap_sentiment = joined_data_filtered[['id', 'sentiment_a', 'sentiment_b']].shape[0]\n","    num_overlap_emotion = joined_data_filtered[['id', 'emotions_a', 'emotions_b']].shape[0]\n","    string_dropped = \"Annotations after droping conneced sentences\"\n","    combined_df = pd.DataFrame({\n","    'Metric': ['Total annotations', string_dropped, 'Number of connected sentences marked', 'Emotion annotations', 'Sentiment annotations', 'Overlap Sentiment', 'Overlap Emotion'],\n","    'Annotator A': [number_of_annotations_a, number_of_annotations_a_connected_s, number_of_annotations_a - number_of_annotations_a_connected_s, annotator_a_emotions_notnull, annotator_a_sentiment_notnull, num_overlap_sentiment, num_overlap_emotion],\n","    'Annotator B': [number_of_annotations_b, number_of_annotations_b_connected_s, number_of_annotations_b - number_of_annotations_b_connected_s, annotator_b_emotions_notnull, annotator_b_sentiment_notnull, num_overlap_sentiment, num_overlap_emotion]\n","})\n","    #  styling\n","    styled_df = combined_df.style.set_properties(**{'text-align': 'center'}).set_table_styles([\n","        {'selector': 'th.col_heading', 'props': 'text-align: center'},\n","        {'selector': 'caption', 'props': [('text-align', 'center'), ('font-size', '11pt'), ('font-weight', 'bold')]}\n","    ])\n","    styled_df = styled_df.hide(axis=\"index\")\n","\n","    display(styled_df)\n","\n","#Logic Funtions:\n","def task_agreement(task, annotator_a_data, annotator_b_data):\n","    global annotator_a_task\n","    global annotator_b_task\n","    if task == 'label':\n","        annotator_a_task = annotator_a_data[['id', f'{task}']].copy()\n","        annotator_b_task = annotator_b_data[['id', f'{task}']].copy()\n","        labelcalc()\n","    else:\n","        annotator_a_task = annotator_a_data[f'{task}']\n","        annotator_b_task = annotator_b_data[f'{task}']\n","        agreement = cohen_kappa_score(annotator_a_task, annotator_b_task)\n","        visualize_agreement_matrix(f'{task}', agreement)\n","\n","def calc_agreement(data,annotator_a,annotator_b,task):\n","  global annotator_a_data\n","  global annotator_b_data\n","  global overlap_ids\n","\n","  # flag for removing connected sentences\n","  if task != 'label':\n","    newdata = filter_following_sentences(data)\n","  else:\n","    newdata = data.copy()\n","  #end of flag\n","\n","  newdata = data\n","  annotator_a_data = filter_by_annotator(newdata, annotator_a)\n","  annotator_b_data = filter_by_annotator(newdata, annotator_b)\n","  if task == 'Stats':\n","    display_stats(newdata)\n","  else:\n","    #calculate overlapping samples\n","    annotator_a_data_notnull = annotator_a_data[annotator_a_data[f'{task}'].notnull()]\n","    annotator_b_data_notnull = annotator_b_data[annotator_b_data[f'{task}'].notnull()]\n","    overlap_ids = set(annotator_a_data_notnull['id']).intersection(set(annotator_b_data_notnull['id']))\n","    annotator_a_data = annotator_a_data[(annotator_a_data['id'].isin(overlap_ids))]\n","    annotator_b_data = annotator_b_data[(annotator_b_data['id'].isin(overlap_ids))]\n","    annotator_a_data = annotator_a_data.astype({'sentiment': str, 'emotions': str})\n","    annotator_b_data = annotator_b_data.astype({'sentiment': str, 'emotions': str})\n","\n","    if len(overlap_ids) > 0:\n","      task_agreement(task, annotator_a_data, annotator_b_data)\n","    else:\n","      print(\"Selected annotators have no overlapping annotations.\")\n","\n","\n","def basic_agreement(task):\n","    joined_data = pd.merge(annotator_a_data, annotator_b_data,on='id', how='inner', suffixes=('_a', '_b'))\n","    joined_data_filtered = joined_data[['id', 'sentiment_a', 'sentiment_b','emotions_a','emotions_b']]\n","    df = joined_data_filtered[['id', f'{task}_a', f'{task}_b']]\n","    agreement_cases = df[df[f'{task}_a'] == df[f'{task}_b']]\n","    return agreement_cases.shape[0] / df.shape[0]\n","\n","def visualize_agreement_matrix(task, kappa):\n","    # Filter the data\n","    joined_data = pd.merge(annotator_a_data, annotator_b_data,on='id', how='inner', suffixes=('_a', '_b'))\n","    joined_data_filtered = joined_data[['id', 'sentiment_a', 'sentiment_b','emotions_a','emotions_b','label_a','label_b']]\n","    joined_data_filtered.head()\n","    df = joined_data_filtered[['id', f'{task}_a', f'{task}_b']]\n","    # Get unique values\n","    values = np.flip(np.sort(df[f'{task}_a'].unique()))\n","    # Create an empty confusion matrix\n","    confusion_matrix = pd.DataFrame(0, index=values, columns=values)\n","    basic_agreement_val = basic_agreement(f'{task}')\n","    # Fill the confusion matrix\n","    for i in values:\n","        for j in values:\n","            confusion_matrix.loc[i, j] = len(df[(df[f'{task}_a'] == i) & (df[f'{task}_b'] == j)])\n","    # Visualize the confusion matrix\n","    min, max = get_vmin_vmax(confusion_matrix)\n","    sns.heatmap(confusion_matrix, cmap='RdYlBu', annot=True, fmt='.5g', vmin=min, vmax=max)\n","    title = f'Agreement Matrix for {task}\\n\\n Cohenâ€™s Kappa: = {kappa:.2f}\\n IAA Basic score: = {basic_agreement_val:.2f}'\n","    title = '\\n'.join(line.center(20) for line in title.split('\\n'))\n","    plt.title(title)\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"UqZ4GkFbiwQS"},"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"184ZG-hQ-V-fVdl2U1bPKKzegJSmK4-oI","timestamp":1689790148663}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f9c0278739d44384b7f6115f81132b4d":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":false,"description":"","description_tooltip":null,"disabled":true,"layout":"IPY_MODEL_50484306835d4769a0b1673e5714f806","placeholder":"â€‹","style":"IPY_MODEL_df4ed84568604c3d8c92dbb916dca9ed","value":"Please click Upload to upload your CSV file"}},"50484306835d4769a0b1673e5714f806":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"auto"}},"df4ed84568604c3d8c92dbb916dca9ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea500a17b2b3442bbf3134204e4f4b3d":{"model_module":"@jupyter-widgets/controls","model_name":"FileUploadModel","model_module_version":"1.5.0","state":{"_counter":0,"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FileUploadModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"FileUploadView","accept":".csv","button_style":"","data":[],"description":"Upload","description_tooltip":null,"disabled":false,"error":"","icon":"upload","layout":"IPY_MODEL_1be51764ff774179a1a1e319065b1185","metadata":[],"multiple":false,"style":"IPY_MODEL_6d7b346751d64e54bb4ba26d4816614e"}},"1be51764ff774179a1a1e319065b1185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d7b346751d64e54bb4ba26d4816614e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"e5f6daf417fb4c32bd32dddc8f7068cd":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Run","disabled":false,"icon":"","layout":"IPY_MODEL_98084dd939f54783922716cf0a2835ed","style":"IPY_MODEL_7a584de7b2d2485e85ab4786ae9df0d8","tooltip":""}},"98084dd939f54783922716cf0a2835ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a584de7b2d2485e85ab4786ae9df0d8":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}}}}},"nbformat":4,"nbformat_minor":0}